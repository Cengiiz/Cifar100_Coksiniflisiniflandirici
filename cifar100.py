# -*- coding: utf-8 -*-
"""Cifar100.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dqf7eHI99lFcUyQ19Azv3fQEMwj6hFqn
"""

from tensorflow.keras import datasets
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from matplotlib.pyplot import text
from keras import layers
from keras import models
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import confusion_matrix

(train_images, train_labels), (test_images, test_labels)= datasets.cifar100.load_data()

df_labels = pd.DataFrame(train_labels,columns=['labels'])
df_values = pd.DataFrame(np.array(list(map(lambda x: x.flatten(), train_images))))

df = pd.concat([df_labels, df_values],axis=1)
df.to_csv('df_train.csv', index=False)

df_tlabels = pd.DataFrame(test_labels,columns=['labels'])
df_tvalues = pd.DataFrame(np.array(list(map(lambda x: x.flatten(), test_images))))

dft = pd.concat([df_tlabels, df_tvalues],axis=1)
dft.to_csv('df_test.csv', index=False)

dftrain = pd.read_csv('/content/df_train.csv')

dftest = pd.read_csv('/content/df_test.csv')

bowl_images = dftrain[(dftrain['labels'] == 10) ].iloc[:,1:].values.flatten().reshape(500,32,32,3)
cup_images = dftrain[(dftrain['labels'] == 28)].iloc[:,1:].values.flatten().reshape(500,32,32,3)
lawn_mower_images = dftrain[(dftrain['labels'] == 41)].iloc[:,1:].values.flatten().reshape(500,32,32,3)
orchid_images = dftrain[(dftrain['labels'] == 54)].iloc[:,1:].values.flatten().reshape(500,32,32,3)
palm_tree_images = dftrain[(dftrain['labels'] == 56)  ].iloc[:,1:].values.flatten().reshape(500,32,32,3)
seal_images = dftrain[ (dftrain['labels'] == 72)].iloc[:,1:].values.flatten().reshape(500,32,32,3)
tank_images = dftrain[(dftrain['labels'] == 85) ].iloc[:,1:].values.flatten().reshape(500,32,32,3)
images = [bowl_images, cup_images, lawn_mower_images, orchid_images, palm_tree_images, seal_images, tank_images]

labels = ["bowl", "cup", "lawn mower", "orchid", "palm tree", "seal", "tank"]
offset_x = -100
offset_y = 20
fig, axes = plt.subplots(len(labels), 10)
for i in range(len(labels)):
    axes[i, 0].text(offset_x, offset_y, labels[i], fontsize=12)
    for j in range(10):
        axes[i, j].imshow(images[i][j])
        axes[i, j].axis(False)

plt.show()

values_train = dftrain[(dftrain['labels'] == 10) | (dftrain['labels'] == 28)|(dftrain['labels'] == 41) | (dftrain['labels'] == 54)|(dftrain['labels'] == 56) | (dftrain['labels'] == 72)| (dftrain['labels'] == 85)].iloc[:,1:].values.flatten().reshape(3500,32,32,3)
labels_train = dftrain[(dftrain['labels'] == 10) | (dftrain['labels'] == 28)|(dftrain['labels'] == 41) | (dftrain['labels'] == 54)|(dftrain['labels'] == 56) | (dftrain['labels'] == 72)| (dftrain['labels'] == 85)]['labels']

values_test = dftest[(dftest['labels'] == 10) | (dftest['labels'] == 28)|(dftest['labels'] == 41) | (dftest['labels'] == 54)|(dftest['labels'] == 56) | (dftest['labels'] == 72)| (dftest['labels'] == 85)].iloc[:,1:].values.flatten().reshape(700,32,32,3)
labels_test = dftest[(dftest['labels'] == 10) | (dftest['labels'] == 28)|(dftest['labels'] == 41) | (dftest['labels'] == 54)|(dftest['labels'] == 56) | (dftest['labels'] == 72)| (dftest['labels'] == 85)]['labels']

model=models.Sequential()
model.add(layers.Conv2D(128,(2,2),activation='relu',input_shape=(32,32,3)))
model.add(layers.AvgPool2D((2,2)))
model.add(layers.Conv2D(256,(2,2),activation='relu'))
model.add(layers.AvgPool2D((2,2)))
model.add(layers.Conv2D(256,(2,2),activation='relu'))
model.add(layers.AvgPool2D((2,2)))
model.add(layers.Conv2D(256,(2,2),activation='relu'))
model.add(layers.AvgPool2D((2,2)))
model.add(layers.Flatten())
model.add(layers.Dense(1024,activation='relu'))
model.add(layers.Dense(7,activation='softmax'))
model.summary()

enc = OneHotEncoder()
enc.fit(labels_train.values.reshape(-1,1))
onehotlabels = enc.transform(labels_train.values.reshape(-1,1)).toarray()

enc.fit(labels_test.values.reshape(-1,1))
onehotlabelstest = enc.transform(labels_test.values.reshape(-1,1)).toarray()

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history=model.fit(values_train,
           onehotlabels,
          epochs=100,
          batch_size=100,
          validation_data=(values_test,onehotlabelstest))

test_history=test_loss,test_acc=model.evaluate(values_test,onehotlabelstest)
test_history

test_predict=model.predict(values_test)
test_round_predict=np.round(test_predict)
onehotlabelstest=np.round(onehotlabelstest)

confusionmatrix=confusion_matrix(onehotlabelstest.argmax(axis=1),test_round_predict.argmax(axis=1))

confusionmatrix

test_round_predict[235]

plt.imshow(values_test[235])
plt.show()

print('test_acc:',test_acc)
print('test_loss:',test_loss)

print(history.history.keys())

plt.figure(5)
plt.plot(history.history['loss'])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.show

history_dict=history.history
loss_values=history_dict['loss']
val_loss_values=history_dict['val_loss']
epochs=range(1,len(loss_values)+1)

plt.figure(1)
plt.plot(epochs,loss_values,'ro',label='Traning Loss')
plt.plot(epochs,val_loss_values,'r',label='Validation Loss')
plt.title('Trainin and validation Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.show

history_dict=history.history
acc=history_dict['accuracy']
val_acc=history_dict['val_accuracy']

plt.figure(2)
plt.plot(epochs,acc,'ro',label='Traning acc')
plt.plot(epochs,val_acc,'r',label='Validation acc')
plt.title('Trainin and validation acc')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.show